<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 2.20.25"/><title data-react-helmet="true"></title><link rel="icon" href="/icons/icon-48x48.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="theme-color" content="#663399"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=edf3d310d67f8284a562bc3a58c3e761"/><link as="script" rel="preload" href="/component---src-templates-blog-template-js-cc24d9c1b25791417d4e.js"/><link as="script" rel="preload" href="/framework-4adb46e364577e67729f.js"/><link as="script" rel="preload" href="/app-dea18c772ec29a14c2d6.js"/><link as="script" rel="preload" href="/webpack-runtime-7373b195b665b8695158.js"/><link as="fetch" rel="preload" href="/page-data/blog/ml/speedChallenge/1/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="blog-post-container"><div class="blog-post"><h1>Speed Challenge from Comma AI</h1><h2>April 26, 2020</h2><div class="blog-post-content"><h1>Speed Challenge</h1>
<p>The <a href="https://github.com/commaai/speedchallenge">challenge</a> involves creating an AI algorithm that accurately predicts the speed of a moving car from dashcam footage. Seems like a decent challenge.</p>
<p>My first thought is to play with the data somehow. I use opencv to open the video file per frame and display it in a cv window. Not sure what to else to do so I run Canny Edge Detection on each frame and render the edges instead. Get something kind of interseting, but not sure if it's relevant.</p>
<p>Next step is to figure out which ML algorithm to use to determine speed. There are so many different network types for different applications.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;"
    >
      <a
    class="gatsby-resp-image-link"
    href="/static/df8059993870d387c7dca66f8c7ce152/00d43/mostNNs.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 150%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Most NN Types"
        title="Most NN Types"
        src="/static/df8059993870d387c7dca66f8c7ce152/fcda8/mostNNs.png"
        srcset="/static/df8059993870d387c7dca66f8c7ce152/12f09/mostNNs.png 148w,
/static/df8059993870d387c7dca66f8c7ce152/e4a3f/mostNNs.png 295w,
/static/df8059993870d387c7dca66f8c7ce152/fcda8/mostNNs.png 590w,
/static/df8059993870d387c7dca66f8c7ce152/efc66/mostNNs.png 885w,
/static/df8059993870d387c7dca66f8c7ce152/00d43/mostNNs.png 1000w"
        sizes="(max-width: 590px) 100vw, 590px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
  </a>
    </span></p>
<p>The goal is to figure out which one of these networks will work for this application. Most of the NN I've been practically exposed to are classification networks. They take an image input and output with a one-hot or a percentage of a prediction for a unique classification. I suppose since the data has a single float for the speed of the car at each frame, we could train a CNN to output a flaot per frame. I suppose the accuracy of the CNN would depend on the kernel chosen. What features are we trying to extract from each image?</p>
<p>Well it's not each image in isolation though. Speed is calculated as distance over time so each frame needs to contribute to the next frame's prediction. I think I'll just run a basic FF neural net on the data and see what happens.</p>
<p>Step 1: Save each frame's pixel data in a numpy array. Training images should be an array of the shape: </p></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/ml/speedChallenge/1";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-dea18c772ec29a14c2d6.js"],"component---src-pages-404-js":["/component---src-pages-404-js-1b99097883aebd88f783.js"],"component---src-pages-index-js":["/component---src-pages-index-js-2cfa07ff7c012a341459.js"],"component---src-pages-page-2-js":["/component---src-pages-page-2-js-519dc76a3c7f2e9bbc2e.js"],"component---src-templates-blog-template-js":["/component---src-templates-blog-template-js-cc24d9c1b25791417d4e.js"]};/*]]>*/</script><script src="/webpack-runtime-7373b195b665b8695158.js" async=""></script><script src="/app-dea18c772ec29a14c2d6.js" async=""></script><script src="/framework-4adb46e364577e67729f.js" async=""></script><script src="/component---src-templates-blog-template-js-cc24d9c1b25791417d4e.js" async=""></script></body></html>